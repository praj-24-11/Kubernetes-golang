Kubernetes LangChain MCP Validation Project: Documentation
Project Overview
This project involves creating a Kubernetes-based application that uses LangChain for AI-driven change management validation, integrated with a Model Context Protocol (MCP) server for additional validation. The deployment is automated using GitHub Actions, and Helm charts manage the Kubernetes resources. Below is a detailed walkthrough of every step, including what each component represents and how networking and Helm charts fit into the picture.
Step-by-Step Breakdown
1. Project Initialization and Requirements
•	What We Did: 
o	We started by defining the project requirements in a requirements.txt file to specify Python dependencies: langchain==0.2.0, openai==0.28.0, and requests==2.31.0.
o	This file tells the Python environment (via pip) which libraries to install for the application.
•	Representation: 
o	langchain: A framework for building applications with language models, used here for validating change requests.
o	openai: Provides the OpenAI API for language model interactions.
o	requests: A library for making HTTP requests to the MCP server.
•	Details: 
o	The requirements.txt is copied into the Docker image during the build process (defined in Dockerfile) to ensure the app runs with the correct dependencies.
2. Dockerfile Creation
•	What We Did: 
o	Created a Dockerfile to containerize the application: 
text
CollapseWrap
Copy
FROM python:3.9-slim
WORKDIR /app
COPY app/ .
RUN pip install --no-cache-dir -r requirements.txt
ENV PORT=8080
EXPOSE 8080
CMD ["python", "main.py"]
•	Representation: 
o	FROM python:3.9-slim: Uses a lightweight Python 3.9 image as the base.
o	COPY app/ .: Copies the application code into the container.
o	RUN pip install: Installs dependencies.
o	EXPOSE 8080: Indicates the port the app listens on (though this is informational; Kubernetes overrides it).
o	CMD ["python", "main.py"]: Starts the Flask app.
•	Networking Details: 
o	The container exposes port 8080, which will be mapped to a Kubernetes service port later.
3. Main Application Logic (main.py)
•	What We Did: 
o	Developed main.py to create a Flask API that validates change requests using LangChain and an MCP server.
•	Representation: 
o	The /validate endpoint accepts POST requests with a change_request JSON field.
o	It uses OpenAI from LangChain to generate a validation response and sends the request to the MCP server via requests.
o	Returns a JSON response indicating success or failure.
•	Details: 
o	Environment variables (OPENAI_API_KEY, MCP_SERVER_URL) are injected from Kubernetes config maps or secrets.
4. Kubernetes Configuration Files
•	What We Did: 
o	Created YAML files for Kubernetes resources: configmap.yaml, deployment.yaml, hpa.yaml, ingress.yaml, secret.yaml, and service.yaml.
•	Representation: 
o	configmap.yaml: Stores non-sensitive configuration (e.g., mcp-server-url) as key-value pairs. 
	Used to inject MCP_SERVER_URL into the pod.
o	deployment.yaml: Defines the pod template, replicas (3), and container image, with environment variables from secrets and config maps. 
	Ensures the app runs with the specified image and resources.
o	hpa.yaml: Configures Horizontal Pod Autoscaling to scale based on CPU utilization (min 3, max 10 replicas, target 80%). 
	Automatically adjusts pod count under load.
o	ingress.yaml: Sets up an ingress controller to route external traffic to the service (e.g., langchain-mcp.example.com). 
	Enables HTTP routing with TLS if configured.
o	secret.yaml: Stores sensitive data like the openai-api-key (base64 encoded). 
	Secures API keys in Kubernetes.
o	service.yaml: Exposes the deployment as a ClusterIP service on port 8080. 
	Provides internal networking within the cluster.
•	Networking Details: 
o	The service.yaml creates a stable IP for pods, accessible via DNS within the cluster.
o	ingress.yaml extends this to external traffic, using the nginx-ingress controller specified in Chart.yaml.
5. Helm Chart Setup
•	What We Did: 
o	Created a Helm chart in the helm/ directory with Chart.yaml, values.yaml, and templates.
•	Representation: 
o	Chart.yaml: Defines the chart metadata (name: langchain-mcp, version: 0.1.0) and dependencies (e.g., nginx-ingress). 
	Manages the chart’s structure and dependencies.
o	values.yaml: Provides default configuration (e.g., replicaCount: 3, image.repository, service.port: 8080, autoscaling settings). 
	Allows customization during deployment.
o	Templates: Helm-rendered YAML files that use .Values to inject dynamic values (e.g., {{ .Release.Name }}, {{ .Values.image.tag }}). 
	Ensures flexibility across environments.
•	Details: 
o	Helm simplifies Kubernetes resource management by templating and packaging.
o	The dependency update command in workflow.yaml ensures the nginx-ingress chart is fetched.
6. GitHub Actions Automation (workflow.yaml)
•	What We Did: 
o	Created workflow.yaml to automate building, validating, and deploying the application.
•	Representation: 
o	Triggers: Runs on push to the main branch.
o	Jobs: build-and-deploy runs on ubuntu-latest with steps: 
	checkout: Fetches the code.
	setup-buildx: Prepares Docker for multi-platform builds.
	login-action: Logs into Docker Hub.
	Build and Push: Builds and pushes the Docker image with the Git SHA tag.
	Set up Kubeconfig: Configures Kubernetes access.
	Validate Kubernetes Resources: Sends YAML files to the MCP server for validation.
	Install Helm and Deploy with Helm: Deploys the chart.
•	Networking Details: 
o	The workflow interacts with Docker Hub (external) and your Kubernetes cluster (via kubeconfig).
o	Validation uses HTTP requests to the MCP server.
7. MCP Server Setup
•	What We Did: 
o	Attempted to set up the MCP server using manusa/kubernetes-mcp-server, which turned out to be a Go project with pre-built binaries.
•	Representation: 
o	The server validates Kubernetes resources and provides a /validate endpoint.
o	We explored using the Windows binary or building from source.
•	Details: 
o	Initially tried npm install (incorrect for Go), then switched to running the binary or building with go build.
o	Required customization to support the /validate endpoint for your workflow.
•	Networking Details: 
o	Runs locally on http://localhost:8080 (default) and can be exposed in the cluster for GitHub Actions to access.
8. Configuration and Secrets
•	What We Did: 
o	Set up GitHub secrets (DOCKER_USERNAME, DOCKER_PASSWORD, OPENAI_API_KEY, KUBE_CONFIG, MCP_SERVER_URL).
•	Representation: 
o	These secrets are injected into the workflow and Kubernetes environment.
o	KUBE_CONFIG enables cluster access, while MCP_SERVER_URL points to the validation server.
•	Details: 
o	Obtained OPENAI_API_KEY from OpenAI’s platform.
o	Generated KUBE_CONFIG from kubectl config view.
o	Defined MCP_SERVER_URL based on the local or cluster-deployed MCP server.
9. Testing and Deployment
•	What We Did: 
o	Tested the application locally and planned cluster deployment.
•	Representation: 
o	Local testing involved running python main.py with environment variables.
o	Cluster deployment is handled by GitHub Actions and Helm.
•	Networking Details: 
o	Local testing uses localhost:8080.
o	Cluster access uses the ingress URL (e.g., langchain-mcp.example.com).
Comprehensive Explanation of Components
Networking
•	ClusterIP Service: Internal communication within the cluster (port 8080).
•	Ingress: External HTTP access with domain routing and optional TLS.
•	Pod Networking: Pods communicate via the service’s IP, managed by Kubernetes’ CNI (e.g., Flannel, Calico).
•	GitHub Actions: Connects to Docker Hub and the Kubernetes cluster over the internet.
Helm Charts
•	Purpose: Automates and parameterizes Kubernetes resource deployment.
•	Templates: Use Go templating (e.g., {{ .Values.replicaCount }}) to generate YAML.
•	Values: Customize deployments without altering templates.
GitHub Actions
•	CI/CD: Continuous integration and deployment pipeline.
•	Automation: Builds, tests, and deploys on code push.
MCP Server
•	Role: Validates Kubernetes YAML files against a context model.
•	Customization: Requires a /validate endpoint for your workflow.

